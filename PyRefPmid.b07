# -*- coding: utf-8 -*-
import argparse
import json
import logging
import re
import tempfile
import textwrap
import time
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple, Set

import requests

# ロギング設定
logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s"
)


# --- 設定クラス ---
class Config:
    """デフォルト設定を管理するクラス"""

    # 正規表現
    PMID_REGEX_PATTERN = r"(?i)\[pm(?:id)?:?\s*(\d+)\](?:\([^)]*\))?"

    # 表示形式
    AUTHOR_THRESHOLD = 0
    CITATION_FORMAT = "({number})"
    REFERENCE_ITEM_FORMAT = "{number}. {authors}. {title} {journal} {year};{volume}:{pages}. doi: {doi}. [{pmid}](https://pubmed.ncbi.nlm.nih.gov/{pmid}/)"
    REFERENCES_HEADER = "References"

    # API設定
    API_BASE_URL = "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/"
    API_REQUEST_DELAY = 0.4
    API_KEY = "3a88fc215344206ea89f04981d824c4ca608"

    # キャッシュ設定
    CACHE_FILENAME = "pyrefpmid_cache.json"
    USE_CACHE = True


# --- 主要クラス ---

class PubMedClient:
    """PubMed API との通信を担当するクラス"""

    def __init__(
        self,
        api_base_url: Optional[str] = None,
        api_key: Optional[str] = None,
        api_delay: Optional[float] = None,
    ):
        self.api_base_url = api_base_url or Config.API_BASE_URL
        self.api_key = api_key
        if self.api_key:
            self.api_delay = 0.1
        else:
            self.api_delay = api_delay or Config.API_REQUEST_DELAY

    def fetch_details(self, pmids: List[str]) -> Tuple[Dict[str, Any], List[str]]:
        """指定された PMID リストの詳細を PubMed API から取得する"""
        if not pmids:
            return {}, []

        chunk_size = 100
        api_details = {}
        api_not_found = []

        logging.info("API で取得する PMID (%s件): %s", len(pmids), pmids)

        for i in range(0, len(pmids), chunk_size):
            chunk = pmids[i : i + chunk_size]
            pmid_string = ",".join(chunk)
            url = f"{self.api_base_url}esummary.fcgi?db=pubmed&id={pmid_string}&retmode=json"
            if self.api_key:
                url += f"&api_key={self.api_key}"

            logging.info(
                "PubMed API にリクエスト中 (%d/%d): %s",
                i + 1,
                len(pmids),
                url,
            )

            try:
                response = requests.get(url)
                response.raise_for_status()
                data = response.json()
                results = data.get("result")

                if not results or "uids" not in results:
                    logging.warning("PubMed API から有効な結果が得られませんでした (Chunk)。")
                    api_not_found.extend(chunk)
                    for pmid in chunk:
                        api_details[pmid] = {"error": "Not found in API response"}
                    continue

                returned_uids = results.get("uids", [])
                self._process_api_results(
                    chunk, returned_uids, results, api_details, api_not_found
                )

            except requests.exceptions.RequestException as e:
                logging.error("PubMed API への接続に失敗しました - %s", e)
                api_not_found.extend(chunk)
                for pmid in chunk:
                    api_details[pmid] = {"error": f"API connection failed: {e}"}
            except Exception as e:
                logging.error("PubMed API データ処理中に予期せぬエラーが発生しました - %s", e)
                api_not_found.extend(chunk)
                for pmid in chunk:
                    api_details[pmid] = {"error": f"Unexpected error: {e}"}

            if i + chunk_size < len(pmids):
                time.sleep(self.api_delay)

        return api_details, list(set(api_not_found))

    def _process_api_results(
        self,
        requested_pmids: List[str],
        returned_uids: List[str],
        results: Dict,
        api_details: Dict,
        api_not_found: List[str],
    ):
        """APIの結果を解析して詳細情報を抽出する"""
        requested_set = set(requested_pmids)
        returned_set = set(returned_uids)
        missing = list(requested_set - returned_set)

        if missing:
            logging.warning("API レスポンスに以下の PMID が含まれていません: %s", missing)
            api_not_found.extend(missing)
            for pmid in missing:
                api_details[pmid] = {"error": "Not found in API response"}

        for pmid in returned_uids:
            if pmid not in results:
                continue

            entry = results[pmid]
            if "error" in entry:
                logging.warning("PMID %s の詳細取得で API エラー: %s", pmid, entry["error"])
                if pmid not in api_not_found:
                    api_not_found.append(pmid)
                api_details[pmid] = entry
                continue

            api_details[pmid] = self._extract_entry_data(pmid, entry)

    def _extract_entry_data(self, pmid: str, entry: Dict) -> Dict[str, Any]:
        """個々のエントリから必要なデータを抽出する"""
        authors_list = entry.get("authors", [])
        author_names = [a.get("name", "N/A") for a in authors_list]

        articleids = entry.get("articleids", [])
        doi = next(
            (
                aid.get("value", "")
                for aid in articleids
                if aid.get("idtype") == "doi"
            ),
            "",
        )
        if not doi and entry.get("elocationid", "").startswith("doi:"):
            doi = entry.get("elocationid", "").replace("doi: ", "")

        return {
            "authors_list": author_names,
            "year": entry.get("pubdate", "").split(" ")[0],
            "title": entry.get("title", "N/A"),
            "journal": entry.get("source", "N/A"),
            "volume": entry.get("volume", ""),
            "issue": entry.get("issue", ""),
            "pages": entry.get("pages", ""),
            "pmid": pmid,
            "doi": doi,
        }


class CacheManager:
    """キャッシュの読み書きを担当するクラス"""

    def __init__(
        self,
        cache_file: Optional[str | Path] = None,
        use_cache: bool = True,
    ):
        self.use_cache = use_cache
        self.cache_data = {}
        self.cache_file: Optional[Path] = None

        if not self.use_cache:
            logging.info("キャッシュは無効化されています。")
            return

        if cache_file:
            path = Path(cache_file)
            if path.is_dir():
                self.cache_file = path / Config.CACHE_FILENAME
            else:
                self.cache_file = path
        else:
            self.cache_file = Path(tempfile.gettempdir()) / Config.CACHE_FILENAME

        self._ensure_cache_dir()
        self.load()

    def _ensure_cache_dir(self):
        """キャッシュディレクトリが存在することを確認する"""
        if self.cache_file and not self.cache_file.parent.exists():
            try:
                self.cache_file.parent.mkdir(parents=True, exist_ok=True)
            except Exception as e:
                logging.warning(
                    "キャッシュディレクトリ作成失敗: %s. 一時フォルダを使用します。", e
                )
                self.cache_file = (
                    Path(tempfile.gettempdir()) / Config.CACHE_FILENAME
                )

    def load(self):
        """キャッシュをロードする"""
        if not self.cache_file or not self.cache_file.exists():
            return

        try:
            with open(self.cache_file, "r", encoding="utf-8") as f:
                self.cache_data = json.load(f)
            logging.info("キャッシュファイルを読み込みました: %s", self.cache_file)
        except Exception as e:
            logging.error("キャッシュ読み込みエラー (%s): %s", self.cache_file, e)
            self.cache_data = {}

    def save(self):
        """キャッシュを保存する"""
        if not self.use_cache or not self.cache_file:
            return

        try:
            with open(self.cache_file, "w", encoding="utf-8") as f:
                json.dump(self.cache_data, f, ensure_ascii=False, indent=2)
            logging.info("キャッシュを保存しました: %s", self.cache_file)
        except Exception as e:
            logging.error("キャッシュ保存エラー (%s): %s", self.cache_file, e)

    def get_details(self, pmids: List[str]) -> Tuple[Dict[str, Any], List[str]]:
        """キャッシュから詳細を取得する"""
        found = {}
        not_found = []

        if not self.use_cache:
            return {}, list(pmids)

        for pmid in pmids:
            item = self.cache_data.get(pmid)
            if item:
                # 著者リストがない場合は再取得対象（古いキャッシュ形式対応）
                if "error" not in item and "authors_list" not in item:
                    not_found.append(pmid)
                else:
                    found[pmid] = item
            else:
                not_found.append(pmid)

        return found, not_found

    def update(self, new_details: Dict[str, Any]):
        """キャッシュを更新する"""
        if self.use_cache:
            self.cache_data.update(new_details)
            self.save()


class CitationParser:
    """Markdown コンテンツの解析を担当するクラス"""

    def __init__(self, pmid_regex_pattern: str | None = None, references_header: str = "References"):
        pattern = pmid_regex_pattern or Config.PMID_REGEX_PATTERN
        self.pmid_regex = re.compile(pattern, flags=re.IGNORECASE)
        self.references_header = references_header or Config.REFERENCES_HEADER

        # ヘッダー検出用正規表現
        self.header_regex = re.compile(
            r"^(#+)\s+(Introduction|Methods|Results|Discussion|Conclusion|Background|Case Report|Abstract|はじめに|方法|結果|考察|結論|背景|症例報告|要旨)",
            re.MULTILINE | re.IGNORECASE,
        )

        escaped_header = re.escape(self.references_header)
        self.remove_refs_regex = re.compile(
            rf"(?m)^#+\s+{escaped_header}\s*\n[\s\S]*?(?=\n#+\s+|\Z)",
            re.IGNORECASE,
        )

    def extract_pmid_groups(
        self, markdown_content: str
    ) -> Tuple[List[Tuple[List[str], Tuple[int, int]]], Dict[str, int]]:
        """PMIDグループを抽出し、マッピングを作成する"""
        matches = list(self.pmid_regex.finditer(markdown_content))
        if not matches:
            return [], {}

        pmid_groups = []
        raw_pmids_in_order = []

        current_group_pmids = []
        current_group_start = -1
        current_group_end = 0

        for match in matches:
            pmid = match.group(1)
            start, end = match.span()

            if not current_group_pmids:
                current_group_pmids.append(pmid)
                current_group_start = start
                current_group_end = end
            else:
                inter_text = markdown_content[current_group_end:start]
                if not inter_text.strip():
                    current_group_pmids.append(pmid)
                    current_group_end = end
                else:
                    pmid_groups.append(
                        (sorted(current_group_pmids, key=int), (current_group_start, current_group_end))
                    )
                    raw_pmids_in_order.extend(sorted(current_group_pmids, key=int))

                    current_group_pmids = [pmid]
                    current_group_start = start
                    current_group_end = end

        if current_group_pmids:
            pmid_groups.append(
                (sorted(current_group_pmids, key=int), (current_group_start, current_group_end))
            )
            raw_pmids_in_order.extend(sorted(current_group_pmids, key=int))

        unique_pmids = list(dict.fromkeys(raw_pmids_in_order))
        pmid_map = {pmid: i + 1 for i, pmid in enumerate(unique_pmids)}

        return pmid_groups, pmid_map

    def detect_header_level(self, markdown_content: str) -> int:
        """主要セクションのヘッダーレベルを検出する"""
        match = self.header_regex.search(markdown_content)
        return len(match.group(1)) if match else 2

    def find_existing_references_section(self, content: str) -> Optional[re.Match]:
        """既存の References セクションを検索する"""
        return self.remove_refs_regex.search(content)


class ReferenceFormatter:
    """引用と参考文献リストの整形を担当するクラス"""

    def __init__(
        self,
        citation_format: str | None = None,
        ref_item_format: str | None = None,
        author_threshold: int = 0,
    ):
        self.citation_format = citation_format or Config.CITATION_FORMAT
        self.ref_item_format = ref_item_format or Config.REFERENCE_ITEM_FORMAT
        self.author_threshold = author_threshold

    def _format_authors(self, authors_list: List[str]) -> str:
        """著者名リストを閾値に従って整形する"""
        if self.author_threshold > 0 and len(authors_list) > self.author_threshold:
            return ", ".join(authors_list[: self.author_threshold]) + ", et al"
        return ", ".join(authors_list)

    def _format_citation_numbers(self, numbers: List[int]) -> str:
        """番号リストを範囲形式に整形する (例: 1-3,5)"""
        if not numbers:
            return ""
        numbers = sorted(set(numbers))
        ranges = []
        if not numbers: return ""

        start = end = numbers[0]
        for n in numbers[1:]:
            if n == end + 1:
                end = n
            else:
                ranges.append(f"{start}-{end}" if end > start + 1 else (f"{start},{end}" if end == start + 1 else f"{start}"))
                start = end = n
        ranges.append(f"{start}-{end}" if end > start + 1 else (f"{start},{end}" if end == start + 1 else f"{start}"))
        return ",".join(ranges)

    def replace_citations(
        self,
        content: str,
        pmid_groups: List[Tuple[List[str], Tuple[int, int]]],
        pmid_map: Dict[str, int],
    ) -> str:
        """本文中の引用箇所を置換する"""
        new_parts = []
        last_end = 0

        for group_pmids, (start, end) in pmid_groups:
            # マップに存在するPMIDのみ番号を取得
            nums = [pmid_map[p] for p in group_pmids if p in pmid_map]
            formatted_nums = self._format_citation_numbers(nums)

            new_parts.append(content[last_end:start])
            if formatted_nums:
                new_parts.append(self.citation_format.replace("{number}", formatted_nums))
            else:
                new_parts.append(content[start:end])
            last_end = end

        new_parts.append(content[last_end:])
        return "".join(new_parts)

    def create_section(self, pmid_map: Dict[str, int], details_map: Dict[str, Any], header: str) -> str:
        """References セクションを作成する"""
        if not details_map:
            return ""

        items = []
        for pmid, number in pmid_map.items():
            details = details_map.get(pmid)
            if details and "error" not in details:
                # 整形時に動的に著者名を生成（thresholdを適用）
                details_copy = details.copy()
                details_copy["authors"] = self._format_authors(details.get("authors_list", []))

                try:
                    items.append(self.ref_item_format.format(number=number, **details_copy))
                except Exception:
                    items.append(f"{number}. [PMID {pmid}] - Format Error")
            else:
                 items.append(f"{number}. [PMID {pmid}] - Load Error")

        if not items:
            return ""
        return f"{header}\n\n" + "\n".join(items)


class PubMedProcessor:
    """各コンポーネントを統合して処理を実行するクラス"""

    def __init__(self, args):
        self.args = args
        self.client = PubMedClient(
            api_key=args.api_key,
            api_delay=args.api_delay
        )
        self.cache = CacheManager(
            cache_file=args.cache_file,
            use_cache=args.use_cache
        )
        self.parser = CitationParser(
            pmid_regex_pattern=args.pmid_regex,
            references_header=args.references_header
        )
        self.formatter = ReferenceFormatter(
            citation_format=args.citation_format,
            ref_item_format=args.ref_item_format,
            author_threshold=args.author_threshold
        )

    def process_file(self, input_path: Path, output_path: Path) -> bool:
        logging.info("処理開始: %s", input_path)
        try:
            with open(input_path, "r", encoding="utf-8") as f:
                content = f.read()
        except Exception as e:
            logging.error("ファイル読み込みエラー: %s", e)
            return False

        # 1. 引用解析
        pmid_groups, pmid_map = self.parser.extract_pmid_groups(content)
        if not pmid_map:
            logging.warning("PMIDが見つかりません。")
            self._handle_no_pmids(input_path, output_path)
            return True

        # 2. データ取得 (キャッシュ -> API)
        pmids = list(pmid_map.keys())
        cached_details, missing_pmids = self.cache.get_details(pmids)
        api_details, not_found = self.client.fetch_details(missing_pmids)

        # 統合
        final_details = {**cached_details, **api_details}
        self.cache.update(api_details)

        # 3. 本文置換
        new_content = self.formatter.replace_citations(content, pmid_groups, pmid_map)

        # 4. References セクション生成
        header_level = self.parser.detect_header_level(content)
        header_str = "#" * header_level + " " + self.parser.references_header
        ref_section = self.formatter.create_section(pmid_map, final_details, header_str)

        # 5. セクション結合
        final_content = self._merge_references(new_content, ref_section)

        # 6. 保存
        try:
            with open(output_path, "w", encoding="utf-8") as f:
                f.write(final_content)
            logging.info("保存完了: %s", output_path)
            return True
        except Exception as e:
            logging.error("保存エラー: %s", e)
            return False

    def _handle_no_pmids(self, input_path, output_path):
        """PMIDがない場合の処理（コピーまたは何もしない）"""
        if input_path != output_path:
            import shutil
            try:
                shutil.copy2(input_path, output_path)
            except Exception as e:
                logging.error("コピーエラー: %s", e)

    def _merge_references(self, content: str, ref_section: str) -> str:
        """本文と参考文献セクションを結合する"""
        match = self.parser.find_existing_references_section(content)
        if match:
            if ref_section:
                logging.info("既存の References セクションを更新")
                return content[: match.start()] + ref_section + content[match.end() :]
            else:
                logging.info("既存の References セクションを削除")
                return content[: match.start()].rstrip() + "\n\n" + content[match.end() :].lstrip("\n")
        else:
            if ref_section:
                logging.info("References セクションを追加")
                return content.rstrip() + "\n\n" + ref_section
            return content



# --- ファイル選択ダイアログ関数 ---
def ask_for_file(
    title: str = "ファイルを選択してください",
    filetypes: Optional[List[Tuple[str, str]]] = None,
) -> Optional[str]:
    """ファイル選択ダイアログを表示してファイルパスを取得する"""
    if filetypes is None:
        filetypes = [("Markdown files", "*.md"), ("All files", "*.*")]

    import tkinter as tk
    from tkinter import filedialog

    root = tk.Tk()
    root.withdraw()
    filepath = filedialog.askopenfilename(title=title, filetypes=filetypes)
    root.destroy()
    if not filepath:
        logging.warning("ファイルが選択されませんでした。")
        return None
    return filepath


def main():
    parser = argparse.ArgumentParser(
        description="Markdown ファイル内の PubMed 引用を処理し、References リストを生成・置換します。",
        formatter_class=argparse.RawTextHelpFormatter,
    )
    # 引数定義 (Config クラスを利用)
    parser.add_argument("input_file", nargs="?", help="入力ファイルパス")
    parser.add_argument("-o", "--output-file", help="出力ファイルパス")
    parser.add_argument("--pmid-regex", default=Config.PMID_REGEX_PATTERN)
    parser.add_argument("--author-threshold", type=int, default=Config.AUTHOR_THRESHOLD)
    parser.add_argument("--citation-format", default=Config.CITATION_FORMAT)
    parser.add_argument("--ref_item_format", default=Config.REFERENCE_ITEM_FORMAT)
    parser.add_argument("--api-delay", type=float, default=None)
    parser.add_argument("--api-key", default=Config.API_KEY)
    parser.add_argument("--references-header", default=Config.REFERENCES_HEADER)
    parser.add_argument("--cache-file", default=None)
    parser.add_argument("--use-cache", type=lambda x: str(x).lower() == "true", default=Config.USE_CACHE)
    parser.add_argument("--no-cache", action="store_false", dest="use_cache")

    args = parser.parse_args()

    # 入力ファイル処理
    input_str = args.input_file
    if not input_str:
        input_str = ask_for_file()
        if not input_str: return

    input_path = Path(input_str)
    if not input_path.is_file():
        logging.error("ファイルが見つかりません: %s", input_path)
        return

    # 出力ファイル処理
    if args.output_file:
        output_path = Path(args.output_file)
        if output_path.is_dir():
            output_path = output_path / f"{input_path.stem}_cited{input_path.suffix}"
    else:
        output_path = input_path.with_name(f"{input_path.stem}_cited{input_path.suffix}")

    if not output_path.parent.exists():
        output_path.parent.mkdir(parents=True, exist_ok=True)

    # 実行
    processor = PubMedProcessor(args)
    processor.process_file(input_path, output_path)

if __name__ == "__main__":
    main()
